Linear regression adalah salah satu dari kasus Supervised Learning.
Ide dari Machine Learning:
<svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 789 314" width="789" height="314"><!-- svg-source:excalidraw --><metadata></metadata><defs><style class="style-fonts">
      @font-face { font-family: Excalifont; src: url(data:font/woff2;base64,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); }</style></defs><rect x="0" y="0" width="789" height="314" fill="#ffffff"></rect><g stroke-linecap="round" transform="translate(299 10) rotate(0 92 26.5)"><path d="M13.25 0 C73.14 0.92, 132.61 -0.61, 170.75 0 M13.25 0 C48.03 1.53, 84.26 1.11, 170.75 0 M170.75 0 C181.52 -1.19, 182.66 2.72, 184 13.25 M170.75 0 C181.17 1.07, 185.61 5.62, 184 13.25 M184 13.25 C184.21 20.24, 183.85 25.8, 184 39.75 M184 13.25 C183.19 21.11, 183.83 31.39, 184 39.75 M184 39.75 C182.65 49.24, 178.04 51.36, 170.75 53 M184 39.75 C183.02 46.6, 178.43 53.57, 170.75 53 M170.75 53 C128.45 55.63, 89.61 55.26, 13.25 53 M170.75 53 C118.77 54.2, 67.54 53.66, 13.25 53 M13.25 53 C4.01 51.68, 0.7 50.52, 0 39.75 M13.25 53 C3.76 50.96, -1.33 50.32, 0 39.75 M0 39.75 C1.55 31.91, 1.98 27.87, 0 13.25 M0 39.75 C-0.08 33.63, -0.56 27.08, 0 13.25 M0 13.25 C-1.41 4.73, 2.77 0.56, 13.25 0 M0 13.25 C-1.29 6.45, 6.66 -0.1, 13.25 0" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(331.68006896972656 24) rotate(0 59.31993103027344 12.5)"><text x="59.31993103027344" y="17.619999999999997" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">Training Set</text></g><g stroke-linecap="round" transform="translate(293 121.5) rotate(0 102 31)"><path d="M15.5 0 C79.5 -0.49, 143.26 -0.88, 188.5 0 M15.5 0 C67.35 0.88, 117.6 0.24, 188.5 0 M188.5 0 C200.3 0.38, 204.46 3.28, 204 15.5 M188.5 0 C198.85 -0.71, 203.11 4.34, 204 15.5 M204 15.5 C204.83 27.34, 201.96 39.83, 204 46.5 M204 15.5 C203.14 23.33, 204.53 30.03, 204 46.5 M204 46.5 C202.36 55.02, 198.5 61.23, 188.5 62 M204 46.5 C202.88 58.89, 198.24 63.95, 188.5 62 M188.5 62 C153.96 61.46, 120.42 61.29, 15.5 62 M188.5 62 C133.09 63.52, 79.12 62.53, 15.5 62 M15.5 62 C3.85 61.08, 0.06 56.57, 0 46.5 M15.5 62 C7.24 62.74, 0.89 55.11, 0 46.5 M0 46.5 C1.21 35.91, 0.36 21.99, 0 15.5 M0 46.5 C0.04 38.84, 0.16 31.15, 0 15.5 M0 15.5 C0.11 5.32, 4.6 -0.17, 15.5 0 M0 15.5 C-1.3 5.85, 4 0.18, 15.5 0" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(306.6600875854492 140) rotate(0 88.33991241455078 12.5)"><text x="88.33991241455078" y="17.619999999999997" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">Learning Algorithm</text></g><g stroke-linecap="round"><g transform="translate(388.8633658055328 69.00000000000001) rotate(0 0.2667538478795741 22.499999999999993)"><path d="M-0.12 0.13 C-0.05 7.55, 0.79 37.23, 0.83 44.68 M0.82 -0.28 C0.81 7.19, 0.49 37.61, 0.55 45.22" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(388.8633658055328 69.00000000000001) rotate(0 0.2667538478795741 22.499999999999993)"><path d="M-7.09 24.05 C-4 32.46, -1.97 38.99, 0.55 45.22 M-7.09 24.05 C-4.66 30.25, -2.59 36.03, 0.55 45.22" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(388.8633658055328 69.00000000000001) rotate(0 0.2667538478795741 22.499999999999993)"><path d="M8.3 24.09 C5.67 32.47, 1.98 38.98, 0.55 45.22 M8.3 24.09 C6.55 30.31, 4.44 36.09, 0.55 45.22" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g></g><mask></mask><g stroke-linecap="round" transform="translate(295 239) rotate(0 102 31)"><path d="M15.5 0 C83.79 3.13, 150.08 1.15, 188.5 0 M15.5 0 C52.09 -2.04, 88.29 -2.25, 188.5 0 M188.5 0 C200.3 1.58, 203.89 6.79, 204 15.5 M188.5 0 C196.55 -1.22, 202.56 5.61, 204 15.5 M204 15.5 C202.66 26.08, 203.24 33.38, 204 46.5 M204 15.5 C204.37 26.38, 204.73 38.36, 204 46.5 M204 46.5 C202.39 57.27, 198.78 60.71, 188.5 62 M204 46.5 C203.76 55.51, 196.63 62.88, 188.5 62 M188.5 62 C150.16 65.41, 107.24 63.8, 15.5 62 M188.5 62 C148.66 59.48, 111.23 59.5, 15.5 62 M15.5 62 C5.65 63.47, -0.32 56.45, 0 46.5 M15.5 62 C2.88 63.6, 1.15 58.75, 0 46.5 M0 46.5 C1.29 39.46, 0.5 34.09, 0 15.5 M0 46.5 C-0.26 36.41, 0.27 28.43, 0 15.5 M0 15.5 C-0.42 6.67, 3.69 1.37, 15.5 0 M0 15.5 C1.21 5.68, 3.09 -1.78, 15.5 0" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(344.8900604248047 245) rotate(0 52.10993957519531 25)"><text x="52.10993957519531" y="17.619999999999997" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">h</text><text x="52.10993957519531" y="42.62" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">(hipotesis)</text></g><g stroke-linecap="round" transform="translate(10 236) rotate(0 102 31)"><path d="M15.5 0 C73.27 -1.63, 126.65 -1.44, 188.5 0 M15.5 0 C58.1 1.25, 102.61 0.95, 188.5 0 M188.5 0 C199.39 0.3, 203.65 4.16, 204 15.5 M188.5 0 C199.74 1.32, 202.61 6.95, 204 15.5 M204 15.5 C203.08 25.03, 204.46 36.27, 204 46.5 M204 15.5 C204.75 23.23, 203.49 29.07, 204 46.5 M204 46.5 C202.78 57.17, 197.84 63.9, 188.5 62 M204 46.5 C202.67 57.56, 197.05 62.8, 188.5 62 M188.5 62 C134.25 61.05, 83.86 64.42, 15.5 62 M188.5 62 C139.77 60.1, 92.1 60.25, 15.5 62 M15.5 62 C3.98 60.94, -1.55 55.93, 0 46.5 M15.5 62 C4.28 64.02, 0.55 57.49, 0 46.5 M0 46.5 C-0.21 37.04, -2.11 22.09, 0 15.5 M0 46.5 C0.66 35.17, -0.49 23.42, 0 15.5 M0 15.5 C0.01 6.03, 5.01 -1.97, 15.5 0 M0 15.5 C-1.28 5.23, 6.97 -2.11, 15.5 0" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(57.9300537109375 242) rotate(0 54.0699462890625 25)"><text x="54.0699462890625" y="17.619999999999997" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">x</text><text x="54.0699462890625" y="42.62" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">(new input)</text></g><g stroke-linecap="round" transform="translate(575 242) rotate(0 102 31)"><path d="M15.5 0 C77.55 0.7, 140.14 -2.2, 188.5 0 M15.5 0 C81.64 -0.17, 147.18 -0.61, 188.5 0 M188.5 0 C200.73 1.63, 203.86 6.65, 204 15.5 M188.5 0 C197.05 1.42, 202.94 4.66, 204 15.5 M204 15.5 C202.35 22.76, 202.36 29.68, 204 46.5 M204 15.5 C203.45 28.59, 204.31 40.19, 204 46.5 M204 46.5 C203.24 58.75, 200.12 61.31, 188.5 62 M204 46.5 C202.35 57.56, 200.93 61.42, 188.5 62 M188.5 62 C120.99 62.13, 52.75 61.28, 15.5 62 M188.5 62 C123.36 62.14, 59.1 61.84, 15.5 62 M15.5 62 C5.9 61.41, 0.22 57.8, 0 46.5 M15.5 62 C6.49 62.31, -0.28 56.59, 0 46.5 M0 46.5 C1.39 36.39, -1.35 25.74, 0 15.5 M0 46.5 C-0.6 36.78, -0.54 25.9, 0 15.5 M0 15.5 C0.99 5.25, 7.14 -0.5, 15.5 0 M0 15.5 C-0.46 6.26, 4.86 1.84, 15.5 0" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(613.6200637817383 248) rotate(0 63.37993621826172 25)"><text x="63.37993621826172" y="17.619999999999997" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">y</text><text x="63.37993621826172" y="42.62" font-family="Excalifont, Xiaolai, sans-serif, Segoe UI Emoji" font-size="20px" fill="#1e1e1e" text-anchor="middle" style="white-space: pre;" direction="ltr" dominant-baseline="alphabetic">(new output)</text></g><g stroke-linecap="round"><g transform="translate(394 187) rotate(0 0.999999999999999 24.999999999999986)"><path d="M-0.13 0.15 C0.1 8.4, 1.26 41.47, 1.7 49.71 M0.8 -0.25 C1.18 8.06, 2.52 41.89, 2.79 50.26" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(394 187) rotate(0 0.999999999999999 24.999999999999986)"><path d="M-6.61 27.1 C-2.92 34.9, -0.34 44.69, 2.79 50.26 M-6.61 27.1 C-4 32.42, -2.23 37.96, 2.79 50.26" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(394 187) rotate(0 0.999999999999999 24.999999999999986)"><path d="M10.48 26.48 C8.02 34.48, 4.47 44.49, 2.79 50.26 M10.48 26.48 C9.14 31.88, 6.98 37.57, 2.79 50.26" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g></g><mask></mask><g stroke-linecap="round"><g transform="translate(219 267) rotate(0 38 1)"><path d="M-0.68 0.53 C11.8 0.88, 61.93 1.64, 74.86 1.89 M1.16 -0.23 C13.99 0.33, 64.4 2.78, 76.97 3.37" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(219 267) rotate(0 38 1)"><path d="M53.1 10.79 C61.12 6.81, 67.18 8, 76.97 3.37 M53.1 10.79 C61.13 8.04, 66.78 6.73, 76.97 3.37" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(219 267) rotate(0 38 1)"><path d="M53.92 -6.29 C61.67 -5.18, 67.48 1.11, 76.97 3.37 M53.92 -6.29 C61.86 -3.9, 67.27 -0.07, 76.97 3.37" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g></g><mask></mask><g stroke-linecap="round"><g transform="translate(504 269) rotate(0 35.5 2)"><path d="M0.83 0.43 C12.95 1.2, 59.82 3.23, 71.66 3.95 M-0.19 -0.39 C11.92 0.63, 59.11 4.93, 71.06 5.46" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(504 269) rotate(0 35.5 2)"><path d="M47.02 12.33 C52.91 11.79, 57.24 10.63, 71.06 5.46 M47.02 12.33 C56.35 9.65, 64.99 7.45, 71.06 5.46" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g><g transform="translate(504 269) rotate(0 35.5 2)"><path d="M48.23 -4.73 C53.77 -1.61, 57.84 0.87, 71.06 5.46 M48.23 -4.73 C57.26 -1.25, 65.46 2.7, 71.06 5.46" stroke="#1e1e1e" stroke-width="2" fill="none"></path></g></g><mask></mask></svg>
Kita mengumpulkan data yang akan digunakan sebagai *training set*, dan dengan suatu *learning algorithm* (algoritma pembelajaran) kita dapatkan suatu fungsi $h$ yang disebut **model**, yang mana bisa memetakan suatu input baru yang belum pernah dilihat untuk menghasilkan output baru juga.
Dalam kasus regresi linear, fungsi $h$ didefinisikan dengan:
$$
h(x)=\theta_{0}+\theta_{1}x, \quad x \in \mathbb{R}
$$
jika $x=x_{1},\dots,x_{J}$ sehingga $x \in \mathbb{R}^J$ maka bisa ditulis:
$$
h(x)= \sum_{j=0}^J\theta_{j}x_{j}
$$
dengan $x_{0}=1$.
Tujuan *training* adalah memilih parameter $\theta$ sehingga meminimalkan:
$$
min_{\theta}\sum_{i=1}^N(h_{\theta}(x^{(i)})-y^{(i)})^2
$$
dengan  $i=1,\dots,N$ menyatakan *data point* atau *features*. Salah satu caranya adalah menggunakan **Gradient Descent** ([[Part 9 - Linear Regression]]).
$$
\theta_{j}:=\theta_{j}-\alpha \frac{d}{d \theta_{j}}J_{\theta}
$$
dengan (sebagai contoh kita punya $1$ data point):
$$
\begin{align}
\frac{d}{d \theta_{j}}J_{\theta} & =\frac{d}{d\theta_{j}}\frac{1}{2}(h_{\theta}(x)-y)^2 \\
 & =2 \frac{1}{2}(h_{\theta}(x)-y)\cdot \frac{d}{d\theta_{j}}(h_{\theta}(x)-y) \\
 & =(h_{\theta}(x)-y)\cdot \frac{d}{d\theta_{j}}(\theta_{0}x_{0}+\dots+\theta _{j}x_{j}+\dots+\theta_{N}x_{N}-y) \\
 & =(h_{\theta}(x)-y)x_{j}
\end{align}
$$
**note:** $J_{\theta}$ adalah fungsi *convex* sehingga *local minimum* juga merupakan *global minimum*.
Metode di atas juga disebut **Batch Gradient Descent**.
Dalam konteks *machine learning*, efisiensi komputasi sangat penting, oleh karenanya sangat bagus untuk mempertimbangkan **Stocastic Gradient Descent (SGD)**.
for i=1 to N {
	for j=0 to J {
		$\theta_{j}:=\theta _j-\alpha(h_{\theta}x^{(i)}-y^{(i)})x_{j}^{(i)}$
	}
}
**note:** Jika banyaknya dataset kecil (100-1k) sehingga penggunaan *batch gradient descent* tidak dipersoalkan maka bisa dipertimbangkan memakai *gradient descent*.
